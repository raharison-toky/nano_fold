{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rahar\\anaconda3\\envs\\neuro\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Sequence\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "import lightning\n",
    "from lightning.fabric import Fabric\n",
    "from dataclasses import dataclass\n",
    "import einx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_PATH = \"training_data/labels.txt\"\n",
    "DEVICE = \"cuda\"\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "with open(TRAINING_PATH) as f:\n",
    "\tfor i in f:\n",
    "\t\tlines.append(i)\n",
    "\n",
    "n_sequences = len(lines)//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "\n",
    "for i in range(n_sequences):\n",
    "\tseq_id,seq_len = (lines[i*3]).split(\" | \")\n",
    "\tassert seq_id[0] == \">\"\n",
    "\tseq_id = seq_id[1:]\n",
    "\tseq_len = int(seq_len)\n",
    "\tseq = lines[i*3+1].strip()\n",
    "\tlabels = lines[i*3+2].strip()\n",
    "\n",
    "\tsequences.append([seq_id,seq,labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'CYS': 'C', 'ASP': 'D', 'SER': 'S', 'GLN': 'Q', 'LYS': 'K',\n",
    "     'ILE': 'I', 'PRO': 'P', 'THR': 'T', 'PHE': 'F', 'ASN': 'N', \n",
    "     'GLY': 'G', 'HIS': 'H', 'LEU': 'L', 'ARG': 'R', 'TRP': 'W', \n",
    "     'ALA': 'A', 'VAL':'V', 'GLU': 'E', 'TYR': 'Y', 'MET': 'M'}\n",
    "\n",
    "amino_acids = list(d.values())\n",
    "\n",
    "amino_to_int_dict = {i:idx+3 for idx,i in enumerate(amino_acids)}\n",
    "amino_to_int_dict[\"<PAD>\"] = 0\n",
    "amino_to_int_dict[\"<MASK>\"] = 1\n",
    "amino_to_int_dict[\"<END>\"] = 0\n",
    "int_to_amino_dict = {v:k for v,k in amino_to_int_dict.items()}\n",
    "\n",
    "secondary_to_int_dict = {\"<PAD>\":2,\"-\":0,\"H\":1,\"<END>\":0}\n",
    "int_to_secondary_dict = {v:k for v,k in secondary_to_int_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_from_dict(sequence,tokenizer_dict,length=None):\n",
    "\n",
    "\tif length is None:\n",
    "\t\tlength = len(sequence)\n",
    "\n",
    "\tseq = []\n",
    "\n",
    "\tfor i in range(length):\n",
    "\n",
    "\t\tif i>len(sequence):\n",
    "\t\t\tseq.append(tokenizer_dict[\"<PAD>\"])\n",
    "\t\telif i == len(sequence):\n",
    "\t\t\tseq.append(tokenizer_dict[\"<END>\"])\n",
    "\t\telse:\n",
    "\t\t\tseq.append(tokenizer_dict[sequence[i]])\n",
    "\n",
    "\treturn torch.tensor(seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "labels = []\n",
    "\n",
    "l_max = 384\n",
    "\n",
    "for seq in sequences:\n",
    "\tif len(seq[1])<=l_max-1:\n",
    "\t\tinputs.append(tokenize_from_dict(seq[1],amino_to_int_dict,l_max))\n",
    "\t\tlabels.append(tokenize_from_dict(seq[2],secondary_to_int_dict,l_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy(sequences,l_max):\n",
    "\n",
    "\tinputs = []\n",
    "\tlabels = []\n",
    "\n",
    "\tfor seq in sequences:\n",
    "\t\tif len(seq[1])<=l_max-1:\n",
    "\t\t\tinputs.append(tokenize_from_dict(seq[1],amino_to_int_dict,l_max))\n",
    "\t\t\tlabels.append(tokenize_from_dict(seq[2],secondary_to_int_dict,l_max))\n",
    "\n",
    "\treturn torch.stack(inputs),torch.stack(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs,labels = get_xy(sequences,384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5326"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "\tn_amino:int\n",
    "\tamino_dim:int\n",
    "\tn_heads:int\n",
    "\tn_layers:int\n",
    "\texpansion_factor:int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorizedConv(lightning.LightningModule):\n",
    "\n",
    "\tdef __init__(self,\n",
    "\t\t\t  in_dim,\n",
    "\t\t\t  feature,\n",
    "\t\t\t  kernel_size):\n",
    "\t\t\n",
    "\t\tsuper().__init__()\n",
    "\t\t\n",
    "\t\tself.conv = nn.Conv1d(in_dim,in_dim,kernel_size=kernel_size,\n",
    "\t\t\t\t\t\tgroups=in_dim,padding=(kernel_size//2))\n",
    "\t\tself.dense = nn.Conv1d(in_dim,feature,1)\n",
    "\t\n",
    "\tdef forward(self,x):\n",
    "\n",
    "\t\tx = einx.rearrange(\"b l d -> b d l\",x)\n",
    "\t\tx = self.conv(x)\n",
    "\t\tx = self.dense(x)\n",
    "\t\tx = einx.rearrange(\"b d l -> b l d\",x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(lightning.LightningModule):\n",
    "\n",
    "\tdef __init__(self,\n",
    "\t\t\t  in_dim:int,\n",
    "\t\t\t  features:list[int],\n",
    "\t\t\t  kernel_size:int):\n",
    "\t\t\n",
    "\t\tsuper().__init__()\n",
    "\t\t\n",
    "\t\tlayers = []\n",
    "\n",
    "\t\tfor feature in features:\n",
    "\t\t\tlayers.append(FactorizedConv(in_dim,feature,kernel_size))\n",
    "\t\t\tin_dim = feature\n",
    "\n",
    "\t\tself.layers = nn.Sequential(*layers)\n",
    "\t\tself.ln = nn.LayerNorm(feature)\n",
    "\n",
    "\tdef forward(self,x):\n",
    "\n",
    "\t\tfor l in self.layers[:-1]:\n",
    "\t\t\tx = F.relu(l(x))\n",
    "\t\tx = self.ln(self.layers[-1](x))\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin_pos_encode(x):\n",
    "\tembeddings = torch.zeros((x.shape)).to(x.device)\n",
    "\tbatch,length,dim = x.shape\n",
    "\tposition = torch.arange(0,length).to(x.device)\n",
    "\tomega = torch.exp(torch.arange(0,dim,2).to(x.device) * math.log(10000)/dim)\n",
    "\tembeddings[:,:,0::2] = torch.sin(einx.multiply(\"l,d -> l d\",position,omega))\n",
    "\tembeddings[:,:,1::2] = torch.cos(einx.multiply(\"l,d -> l d\",position,omega))\n",
    "\n",
    "\treturn embeddings + x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Rotary(torch.nn.Module):\n",
    "    def __init__(self, dim, base=10000):\n",
    "        super().__init__()\n",
    "        inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        self.register_buffer(\"inv_freq\", inv_freq)\n",
    "        self.seq_len_cached = None\n",
    "        self.cos_cached = None\n",
    "        self.sin_cached = None\n",
    "\n",
    "    def forward(self, x, seq_dim=1):\n",
    "        seq_len = x.shape[seq_dim]\n",
    "        if seq_len != self.seq_len_cached:\n",
    "            self.seq_len_cached = seq_len\n",
    "            t = torch.arange(x.shape[seq_dim], device=x.device).type_as(self.inv_freq)\n",
    "            freqs = torch.einsum(\"i,j->ij\", t, self.inv_freq)\n",
    "            emb = torch.cat((freqs, freqs), dim=-1).to(x.device)\n",
    "            self.cos_cached = emb.cos()[:, None, None, :]\n",
    "            self.sin_cached = emb.sin()[:, None, None, :]\n",
    "        return self.cos_cached, self.sin_cached\n",
    "\n",
    "\n",
    "# rotary pos emb helpers:\n",
    "\n",
    "def rotate_half(x):\n",
    "    x1, x2 = x[..., : x.shape[-1] // 2], x[..., x.shape[-1] // 2 :]\n",
    "    return torch.cat(\n",
    "        (-x2, x1), dim=x1.ndim - 1\n",
    "    )  # dim=-1 triggers a bug in torch < 1.8.0\n",
    "\n",
    "\n",
    "@torch.jit.script\n",
    "def apply_rotary_pos_emb(q, k, cos, sin):\n",
    "    return (q * cos) + (rotate_half(q) * sin), (k * cos) + (rotate_half(k) * sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedMHA(lightning.LightningModule):\n",
    "\n",
    "\tdef __init__(self,\n",
    "\t\t\t  hidden_dim:int,\n",
    "\t\t\t  heads:int):\n",
    "\t\t\n",
    "\t\tsuper().__init__()\n",
    "\t\t\n",
    "\t\tself.proj = nn.Linear(hidden_dim,hidden_dim*3)\n",
    "\t\tself.heads = heads\n",
    "\t\n",
    "\tdef forward(self,x,mask):\n",
    "\n",
    "\t\tproj = self.proj(x)\n",
    "\n",
    "\t\tq,k,v = einx.rearrange(\"b l (k d) -> k b l d\",proj,k=3)\n",
    "\n",
    "\t\tq = q * ((q.shape[-1] // self.heads) ** -0.5)\n",
    "\t\tattn = einx.dot(\"b q (h c), b k (h c) -> b q k h\", q, k, h=self.heads)\n",
    "\n",
    "\t\tattn = einx.where(\"b k, b q k h,\", mask, attn, -torch.inf)\n",
    "\n",
    "\t\tattn = einx.softmax(\"b q [k] h\", attn)\n",
    "\t\ty = einx.dot(\"b q k h, b k (h c) -> b q (h c)\", attn, v)\n",
    "\n",
    "\t\treturn x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROPEMaskedMHA(lightning.LightningModule):\n",
    "\n",
    "\tdef __init__(self,\n",
    "\t\t\t  hidden_dim:int,\n",
    "\t\t\t  heads:int):\n",
    "\t\t\n",
    "\t\tsuper().__init__()\n",
    "\t\t\n",
    "\t\tself.proj = nn.Linear(hidden_dim,hidden_dim*3)\n",
    "\t\tself.heads = heads\n",
    "\t\tself.rope = Rotary(hidden_dim//heads)\n",
    "\n",
    "\t\n",
    "\tdef forward(self,x,mask):\n",
    "\n",
    "\t\tproj = self.proj(x)\n",
    "\n",
    "\t\tq,k,v = einx.rearrange(\"b l (k h d) -> k l b h d\",proj,k=3,h=self.heads)\n",
    "\n",
    "\t\tcos,sin = self.rope(x)\n",
    "\n",
    "\t\tq,k = apply_rotary_pos_emb(q,k,cos,sin)\n",
    "\n",
    "\t\tq = q * ((q.shape[-1]) ** -0.5)\n",
    "\t\tattn = einx.dot(\"l1 b h c, l2 b h c -> b l1 l2 h\", q, k, h=self.heads)\n",
    "\n",
    "\t\tattn = einx.where(\"b k, b q k h,\", mask, attn, -torch.inf)\n",
    "\n",
    "\t\tattn = einx.softmax(\"b q [k] h\", attn)\n",
    "\t\ty = einx.dot(\"b q k h, k b h c -> b q (h c)\", attn, v)\n",
    "\n",
    "\t\treturn x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(lightning.LightningModule):\n",
    "\n",
    "\tdef __init__(self,\n",
    "\t\t\t  hidden_dim:int,\n",
    "\t\t\t  heads:int,\n",
    "\t\t\t  expansion_factor:int):\n",
    "\t\t\n",
    "\t\tsuper().__init__()\n",
    "\t\t\n",
    "\t\tself.mha = ROPEMaskedMHA(hidden_dim,heads)\n",
    "\t\tself.mlp = MLP(hidden_dim,[hidden_dim*expansion_factor,hidden_dim],kernel_size=3)\n",
    "\t\tself.mha_ln = nn.LayerNorm(hidden_dim)\n",
    "\t\tself.mlp_ln = nn.LayerNorm(hidden_dim)\n",
    "\t\tself.drop = nn.Dropout(0.1)\n",
    "\n",
    "\tdef forward(self,x,mask):\n",
    "\n",
    "\t\tx = x + self.drop(self.mha_ln(self.mha(x,mask))) + self.drop(self.mlp_ln(self.mlp(x)))\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderBlock(32,4,2)\n",
    "x = torch.randn((16,384,32))\n",
    "mask = torch.ones((16,384),dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(lightning.LightningModule):\n",
    "\n",
    "\tdef __init__(self,\n",
    "\t\t\t  n_amino:int,\n",
    "\t\t\t  amino_dim:int,\n",
    "\t\t\t  n_heads:int,\n",
    "\t\t\t  n_layers:int,\n",
    "\t\t\t  hidden_dim:int,\n",
    "\t\t\t  expansion_factor:int):\n",
    "\t\t\n",
    "\t\tsuper().__init__()\n",
    "\t\t\n",
    "\t\tself.embeddings = nn.Embedding(n_amino,amino_dim)\n",
    "\t\tlayers = []\n",
    "\n",
    "\t\tfor _ in range(n_layers):\n",
    "\t\t\tlayers.append(EncoderBlock(hidden_dim,n_heads,expansion_factor))\n",
    "\n",
    "\t\tself.layers = nn.Sequential(*layers)\n",
    "\t\tself.masked_lm_head = nn.Linear(hidden_dim,n_amino)\n",
    "\t\tself.structure_head = nn.Linear(hidden_dim,2)\n",
    "\n",
    "\tdef forward(self,x,mask):\n",
    "\n",
    "\t\tx = self.embeddings(x)\n",
    "\t\tx = sin_pos_encode(x)\n",
    "\n",
    "\t\tfor h in self.layers:\n",
    "\t\t\tx = h(x,mask)\n",
    "\n",
    "\t\treturn x\n",
    "\t\n",
    "\tdef lm_forward(self,x,mask):\n",
    "\n",
    "\t\tx = self(x,mask)\n",
    "\t\tx = self.masked_lm_head(x)\n",
    "\t\treturn x\n",
    "\t\n",
    "\tdef structure_forward(self,x,mask):\n",
    "\n",
    "\t\tx = self(x,mask)\n",
    "\t\tx = self.structure_head(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyena(lightning.LightningModule):\n",
    "\n",
    "\tdef __init__(self,\n",
    "\t\t\t  hidden_dim:int,\n",
    "\t\t\t  kernel_size:int):\n",
    "\t\t\n",
    "\t\tsuper().__init__()\n",
    "\t\t\n",
    "\t\tself.k1 = nn.Conv1d(hidden_dim,hidden_dim,kernel_size,\n",
    "\t\t\t\t\t  groups=hidden_dim,padding=kernel_size//2)\n",
    "\t\tself.k2 = nn.Conv1d(hidden_dim,hidden_dim,kernel_size,\n",
    "\t\t\t\t\t  groups=hidden_dim,padding=kernel_size//2)\n",
    "\t\t\n",
    "\t\tself.proj  = nn.Linear(hidden_dim,3*hidden_dim)\n",
    "\n",
    "\tdef forward(self,x,mask):\n",
    "\n",
    "\t\tproj = self.proj(x)\n",
    "\t\tq,k,v = einx.rearrange(\"b l (k d) -> k b d l\",proj,k=3)\n",
    "\t\ty = F.sigmoid(self.k1(q))\n",
    "\t\ty =  v*self.k2(k*y)\n",
    "\t\ty = einx.rearrange(\"b d l -> b l d\",y)\n",
    "\t\treturn y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyenaBlock(lightning.LightningModule):\n",
    "\n",
    "\tdef __init__(self,\n",
    "\t\t\t  hidden_dim:int,\n",
    "\t\t\t  kernel_size:int):\n",
    "\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.hyena_operator = Hyena(hidden_dim,kernel_size)\n",
    "\t\tself.mlp = MLP(hidden_dim,[hidden_dim,hidden_dim],3)\n",
    "\t\tself.ln = nn.LayerNorm(hidden_dim)\n",
    "\t\tself.drop = nn.Dropout(0.1)\n",
    "\n",
    "\tdef forward(self,x,mask):\n",
    "\n",
    "\t\tx = x + self.drop(self.ln(self.hyena_operator(x,mask))) + self.drop(self.ln(self.mlp(x)))\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyenaFormer(lightning.LightningModule):\n",
    "\n",
    "\tdef __init__(self,\n",
    "\t\t\t  n_amino:int,\n",
    "\t\t\t  amino_dim:int,\n",
    "\t\t\t  kernel_size:int,\n",
    "\t\t\t  n_layers:int):\n",
    "\n",
    "\t\tsuper().__init__()\n",
    "\t\t\n",
    "\t\tself.embeddings = nn.Embedding(n_amino,amino_dim)\n",
    "\t\tlayers = []\n",
    "\n",
    "\t\tfor _ in range(n_layers):\n",
    "\t\t\tlayers.append(HyenaBlock(amino_dim,kernel_size))\n",
    "\n",
    "\t\tself.layers = nn.Sequential(*layers)\n",
    "\t\tself.masked_lm_head = nn.Linear(amino_dim,n_amino)\n",
    "\t\tself.structure_head = nn.Linear(amino_dim,2)\n",
    "\n",
    "\tdef forward(self,x,mask):\n",
    "\n",
    "\t\tx = self.embeddings(x)\n",
    "\n",
    "\t\tfor h in self.layers:\n",
    "\t\t\tx = h(x,mask)\n",
    "\n",
    "\t\treturn x\n",
    "\t\n",
    "\tdef lm_forward(self,x,mask):\n",
    "\n",
    "\t\tx = self(x,mask)\n",
    "\t\tx = self.masked_lm_head(x)\n",
    "\t\treturn x\n",
    "\t\n",
    "\tdef structure_forward(self,x,mask):\n",
    "\n",
    "\t\tx = self(x,mask)\n",
    "\t\tx = self.structure_head(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrippedHyena(lightning.LightningModule):\n",
    "\n",
    "\tdef __init__(self,\n",
    "\t\t\t  n_amino:int,\n",
    "\t\t\t  amino_dim:int,\n",
    "\t\t\t  kernel_size:int,\n",
    "\t\t\t  n_layers:int):\n",
    "\n",
    "\t\tsuper().__init__()\n",
    "\t\t\n",
    "\t\tself.embeddings = nn.Embedding(n_amino,amino_dim)\n",
    "\t\tlayers = []\n",
    "\n",
    "\t\tfor _ in range(n_layers//2):\n",
    "\t\t\tlayers.append(HyenaBlock(amino_dim,kernel_size))\n",
    "\t\t\tlayers.append(EncoderBlock(amino_dim,4,2))\n",
    "\n",
    "\t\tself.layers = nn.Sequential(*layers)\n",
    "\t\tself.masked_lm_head = nn.Linear(amino_dim,n_amino)\n",
    "\t\tself.structure_head = nn.Linear(amino_dim,2)\n",
    "\n",
    "\tdef forward(self,x,mask):\n",
    "\n",
    "\t\tx = self.embeddings(x)\n",
    "\n",
    "\t\tfor h in self.layers:\n",
    "\t\t\tx = h(x,mask)\n",
    "\n",
    "\t\treturn x\n",
    "\t\n",
    "\tdef lm_forward(self,x,mask):\n",
    "\n",
    "\t\tx = self(x,mask)\n",
    "\t\tx = self.masked_lm_head(x)\n",
    "\t\treturn x\n",
    "\t\n",
    "\tdef structure_forward(self,x,mask):\n",
    "\n",
    "\t\tx = self(x,mask)\n",
    "\t\tx = self.structure_head(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(lightning.LightningModule):\n",
    "\n",
    "\tdef __init__(self,\n",
    "\t\t\tn_amino:int,\n",
    "\t\t\tamino_dim:int,\n",
    "\t\t\tn_layers:int,\n",
    "\t\t\tkernel_size:int):\n",
    "\t\t\n",
    "\t\tsuper().__init__()\n",
    "\t\t\n",
    "\t\tself.embeddings = nn.Embedding(n_amino,amino_dim)\n",
    "\t\tlayers = []\n",
    "\n",
    "\t\tfor _ in range(n_layers):\n",
    "\t\t\tlayers.append(FactorizedConv(amino_dim,amino_dim,kernel_size))\n",
    "\t\t\t#layers.append(nn.Conv1d(amino_dim,amino_dim,kernel_size,padding=kernel_size//2))\n",
    "\n",
    "\t\tself.layers = nn.Sequential(*layers)\n",
    "\t\tself.masked_lm_head = nn.Linear(amino_dim,n_amino)\n",
    "\t\tself.structure_head = nn.Linear(amino_dim,2)\n",
    "\t\tself.drop = nn.Dropout(0.1)\n",
    "\n",
    "\tdef forward(self,x,mask):\n",
    "\n",
    "\t\tx = self.embeddings(x)\n",
    "\n",
    "\t\t#x = einx.rearrange(\"b l d -> b d l\",x)\n",
    "\t\tfor h in self.layers:\n",
    "\t\t\tx = F.relu(self.drop(h(x)))\n",
    "\n",
    "\t\t#x = einx.rearrange(\"b d l -> b l d\",x)\n",
    "\n",
    "\t\treturn x\n",
    "\t\n",
    "\tdef lm_forward(self,x,mask):\n",
    "\n",
    "\t\tx = self(x,mask)\n",
    "\t\tx = self.masked_lm_head(x)\n",
    "\t\treturn x\n",
    "\t\n",
    "\tdef structure_forward(self,x,mask):\n",
    "\n",
    "\t\tx = self(x,mask)\n",
    "\t\tx = self.structure_head(x)\n",
    "\t\treturn x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(lightning.LightningModule):\n",
    "\n",
    "\tdef __init__(self,\n",
    "\t\t\tn_amino:int,\n",
    "\t\t\tamino_dim:int,\n",
    "\t\t\tn_layers:int,):\n",
    "\t\t\n",
    "\t\tsuper().__init__()\n",
    "\t\t\n",
    "\t\tself.embeddings = nn.Embedding(n_amino,amino_dim)\n",
    "\t\tself.layers = nn.LSTM(amino_dim,amino_dim,n_layers,batch_first=True,\n",
    "\t\t\t\t\t\tbidirectional=True)\n",
    "\t\tself.masked_lm_head = nn.Linear(amino_dim*2,n_amino)\n",
    "\t\tself.structure_head = nn.Linear(amino_dim*2,2)\n",
    "\n",
    "\tdef forward(self,x,mask):\n",
    "\n",
    "\t\tx = self.embeddings(x)\n",
    "\t\tout,(h,c) = self.layers(x)\n",
    "\t\treturn out\n",
    "\t\n",
    "\tdef lm_forward(self,x,mask):\n",
    "\n",
    "\t\tx = self(x,mask)\n",
    "\t\tx = self.masked_lm_head(x)\n",
    "\t\treturn x\n",
    "\t\n",
    "\tdef structure_forward(self,x,mask):\n",
    "\n",
    "\t\tx = self(x,mask)\n",
    "\t\tx = self.structure_head(x)\n",
    "\t\treturn x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "\tn_amino=len(amino_to_int_dict),\n",
    "\tamino_dim=32,\n",
    "\thidden_dim=32,\n",
    "\tn_heads=4,\n",
    "\tn_layers=6,\n",
    "\texpansion_factor=2\n",
    ")\n",
    "\n",
    "cnn_model = CNN(len(amino_to_int_dict),32,8,5)\n",
    "\n",
    "lstm_model = LSTM(len(amino_to_int_dict),32,2)\n",
    "\n",
    "hyena_model = StrippedHyena(len(amino_to_int_dict),64,31,8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StrippedHyena(\n",
       "  (embeddings): Embedding(23, 64)\n",
       "  (layers): Sequential(\n",
       "    (0): HyenaBlock(\n",
       "      (hyena_operator): Hyena(\n",
       "        (k1): Conv1d(64, 64, kernel_size=(31,), stride=(1,), padding=(15,), groups=64)\n",
       "        (k2): Conv1d(64, 64, kernel_size=(31,), stride=(1,), padding=(15,), groups=64)\n",
       "        (proj): Linear(in_features=64, out_features=192, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): FactorizedConv(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64)\n",
       "            (dense): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): FactorizedConv(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64)\n",
       "            (dense): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): EncoderBlock(\n",
       "      (mha): ROPEMaskedMHA(\n",
       "        (proj): Linear(in_features=64, out_features=192, bias=True)\n",
       "        (rope): Rotary()\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): FactorizedConv(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64)\n",
       "            (dense): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): FactorizedConv(\n",
       "            (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
       "            (dense): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (mha_ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): HyenaBlock(\n",
       "      (hyena_operator): Hyena(\n",
       "        (k1): Conv1d(64, 64, kernel_size=(31,), stride=(1,), padding=(15,), groups=64)\n",
       "        (k2): Conv1d(64, 64, kernel_size=(31,), stride=(1,), padding=(15,), groups=64)\n",
       "        (proj): Linear(in_features=64, out_features=192, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): FactorizedConv(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64)\n",
       "            (dense): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): FactorizedConv(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64)\n",
       "            (dense): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): EncoderBlock(\n",
       "      (mha): ROPEMaskedMHA(\n",
       "        (proj): Linear(in_features=64, out_features=192, bias=True)\n",
       "        (rope): Rotary()\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): FactorizedConv(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64)\n",
       "            (dense): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): FactorizedConv(\n",
       "            (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
       "            (dense): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (mha_ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): HyenaBlock(\n",
       "      (hyena_operator): Hyena(\n",
       "        (k1): Conv1d(64, 64, kernel_size=(31,), stride=(1,), padding=(15,), groups=64)\n",
       "        (k2): Conv1d(64, 64, kernel_size=(31,), stride=(1,), padding=(15,), groups=64)\n",
       "        (proj): Linear(in_features=64, out_features=192, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): FactorizedConv(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64)\n",
       "            (dense): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): FactorizedConv(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64)\n",
       "            (dense): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): EncoderBlock(\n",
       "      (mha): ROPEMaskedMHA(\n",
       "        (proj): Linear(in_features=64, out_features=192, bias=True)\n",
       "        (rope): Rotary()\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): FactorizedConv(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64)\n",
       "            (dense): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): FactorizedConv(\n",
       "            (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
       "            (dense): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (mha_ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): HyenaBlock(\n",
       "      (hyena_operator): Hyena(\n",
       "        (k1): Conv1d(64, 64, kernel_size=(31,), stride=(1,), padding=(15,), groups=64)\n",
       "        (k2): Conv1d(64, 64, kernel_size=(31,), stride=(1,), padding=(15,), groups=64)\n",
       "        (proj): Linear(in_features=64, out_features=192, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): FactorizedConv(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64)\n",
       "            (dense): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): FactorizedConv(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64)\n",
       "            (dense): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): EncoderBlock(\n",
       "      (mha): ROPEMaskedMHA(\n",
       "        (proj): Linear(in_features=64, out_features=192, bias=True)\n",
       "        (rope): Rotary()\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): FactorizedConv(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64)\n",
       "            (dense): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): FactorizedConv(\n",
       "            (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
       "            (dense): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (mha_ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (masked_lm_head): Linear(in_features=64, out_features=23, bias=True)\n",
       "  (structure_head): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyena_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  | Name           | Type       | Params\n",
       "----------------------------------------------\n",
       "0 | embeddings     | Embedding  | 1.5 K \n",
       "1 | layers         | Sequential | 223 K \n",
       "2 | masked_lm_head | Linear     | 1.5 K \n",
       "3 | structure_head | Linear     | 130   \n",
       "----------------------------------------------\n",
       "226 K     Trainable params\n",
       "0         Non-trainable params\n",
       "226 K     Total params\n",
       "0.906     Total estimated model params size (MB)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelSummary(hyena_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  | Name           | Type      | Params\n",
       "---------------------------------------------\n",
       "0 | embeddings     | Embedding | 736   \n",
       "1 | layers         | LSTM      | 42.0 K\n",
       "2 | masked_lm_head | Linear    | 1.5 K \n",
       "3 | structure_head | Linear    | 130   \n",
       "---------------------------------------------\n",
       "44.3 K    Trainable params\n",
       "0         Non-trainable params\n",
       "44.3 K    Total params\n",
       "0.177     Total estimated model params size (MB)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelSummary(lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  | Name           | Type       | Params\n",
       "----------------------------------------------\n",
       "0 | embeddings     | Embedding  | 736   \n",
       "1 | layers         | Sequential | 10.0 K\n",
       "2 | masked_lm_head | Linear     | 759   \n",
       "3 | structure_head | Linear     | 66    \n",
       "4 | drop           | Dropout    | 0     \n",
       "----------------------------------------------\n",
       "11.5 K    Trainable params\n",
       "0         Non-trainable params\n",
       "11.5 K    Total params\n",
       "0.046     Total estimated model params size (MB)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelSummary(cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  | Name           | Type       | Params\n",
       "----------------------------------------------\n",
       "0 | embeddings     | Embedding  | 736   \n",
       "1 | layers         | Sequential | 47.6 K\n",
       "2 | masked_lm_head | Linear     | 759   \n",
       "3 | structure_head | Linear     | 66    \n",
       "----------------------------------------------\n",
       "49.2 K    Trainable params\n",
       "0         Non-trainable params\n",
       "49.2 K    Total params\n",
       "0.197     Total estimated model params size (MB)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelSummary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x, num_classes):\n",
    "    return torch.eye(num_classes).to(x.device)[x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def masked_accuracy(logits, labels, mask):\n",
    "    predictions = torch.argmax(logits, axis=-1)\n",
    "    correct_predictions = (predictions == labels) * mask\n",
    "    accuracy = torch.sum(correct_predictions) / torch.sum(mask)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(x,y,p):\n",
    "\n",
    "\tpermutations = torch.randperm(len(x))\n",
    "\tp = int(len(x)*p)\n",
    "\n",
    "\treturn x[permutations[:p]],y[permutations[:p]],x[permutations[p:]],y[permutations[p:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test,y_test,x_train,y_train = train_val_split(inputs,labels,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_idx(n:int,\n",
    "\t\t\t\t  batch_size:int,\n",
    "\t\t\t\t  shuffle:bool=True):\n",
    "\n",
    "\tif shuffle:\n",
    "\t\tpermutations = torch.randperm(n)\n",
    "\telse:\n",
    "\t\tpermutations = torch.arange(n)\n",
    "\t\n",
    "\tpermutations = permutations[0:batch_size*(n//batch_size)]\n",
    "\tbatches = einx.rearrange(\"(n b) -> n b\",permutations,b=batch_size)\n",
    "\n",
    "\treturn batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_from_list(x,values):\n",
    "\n",
    "\tmask = torch.zeros_like(x,dtype=torch.bool)\n",
    "\n",
    "\tfor i in values:\n",
    "\t\tmask += (x == i)\n",
    "\n",
    "\treturn mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_train(fabric,\n",
    "\t\t\t\tmodel:Transformer,\n",
    "\t\t\t\tmask_function,\n",
    "\t\t\t\tx_train,\n",
    "\t\t\t\ty_train,\n",
    "\t\t\t\tx_test,\n",
    "\t\t\t\ty_test,\n",
    "\t\t\t\tbatch_size,\n",
    "\t\t\t\tn_epochs,):\n",
    "\t\n",
    "\tloss_fn = nn.CrossEntropyLoss(reduce=True,ignore_index=-100)\n",
    "\t\n",
    "\tdef loss_acc(fabric,\n",
    "\t\t\t  model,\n",
    "\t\t\t  x_batch,\n",
    "\t\t\t  y_batch,\n",
    "\t\t\t  model_mask,\n",
    "\t\t\t  loss_mask):\n",
    "\t\t\t\n",
    "\t\twith fabric.autocast():\n",
    "\n",
    "\t\t\tx_batch = x_batch.to(DEVICE)\n",
    "\t\t\ty_batch = y_batch.to(DEVICE)\n",
    "\t\t\tmodel_mask = model_mask.to(DEVICE)\n",
    "\t\t\tloss_mask = loss_mask.to(DEVICE)\n",
    "\t\t\n",
    "\t\t\ty_pred = model.structure_forward(x_batch,model_mask)\n",
    "\t\t\ty_batch[torch.logical_not(loss_mask)] = -100\n",
    "\t\t\tloss = loss_fn(einx.rearrange(\"b l c -> b c l\",y_pred),y_batch)\n",
    "\t\t\tacc = masked_accuracy(y_pred,y_batch,loss_mask)\n",
    "\t\treturn loss,acc\n",
    "\n",
    "\t\n",
    "\tdef val_loop(fabric,\n",
    "\t\t\t  model:Transformer,\n",
    "\t\t\t  x_test,\n",
    "\t\t\t  y_test,\n",
    "\t\t\t  batch_size,):\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tbatches = get_batch_idx(len(x_test),batch_size,False)\n",
    "\n",
    "\t\tval_losses = []\n",
    "\t\tval_acc = []\n",
    "\n",
    "\t\tmodel.eval()\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\n",
    "\t\t\tfor b,indices in enumerate(batches):\n",
    "\n",
    "\t\t\t\tx_batch = x_test[indices]\n",
    "\t\t\t\ty_batch = y_test[indices]\n",
    "\n",
    "\t\t\t\tpad_mask = mask_from_list(x_batch,[0,1])\n",
    "\n",
    "\t\t\t\tmasked = mask_function(pad_mask)\n",
    "\n",
    "\t\t\t\tloss,acc = loss_acc(fabric,model,x_batch,y_batch,masked,masked)\n",
    "\t\t\t\tval_losses.append(loss.item())\n",
    "\t\t\t\tval_acc.append(acc.item())\n",
    "\n",
    "\t\tmodel.train()\n",
    "\n",
    "\t\treturn np.mean(val_losses),np.mean(val_acc)\n",
    "\t\n",
    "\toptimizer = torch.optim.AdamW(model.parameters(),\n",
    "\t\t\t\t\t\t\t   lr=1E-3,\n",
    "\t\t\t\t\t\t\t   weight_decay=1E-1)\n",
    "\t\n",
    "\tmodel,optimizer = fabric.setup(model,optimizer)\n",
    "\n",
    "\tval_acc_results = []\n",
    "\ttrain_acc_results = []\n",
    "\n",
    "\tfor epoch in range(n_epochs):\n",
    "\n",
    "\t\tbatches = get_batch_idx(len(x_train),batch_size,True)\n",
    "\n",
    "\t\tlosses = []\n",
    "\t\taccuracies = []\n",
    "\n",
    "\t\tfor b,indices in enumerate(batches):\n",
    "\n",
    "\t\t\tx_batch = x_train[indices]\n",
    "\t\t\ty_batch = y_train[indices]\n",
    "\n",
    "\t\t\t# mask pad tokens\n",
    "\n",
    "\t\t\tpad_mask = mask_from_list(x_batch,[0,1])\n",
    "\n",
    "\t\t\t# mask (for language modeling)\n",
    "\n",
    "\t\t\tmasked = mask_function(pad_mask)\n",
    "\n",
    "\t\t\tloss,acc = loss_acc(fabric,model,x_batch,y_batch,masked,masked)\n",
    "\n",
    "\t\t\tfabric.backward(loss)\n",
    "\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\t\tlosses.append(loss.item())\n",
    "\t\t\taccuracies.append(acc.item())\n",
    "\n",
    "\t\tval_loss,val_acc = val_loop(fabric,model,x_test,y_test,batch_size,)\n",
    "\n",
    "\t\ttrain_acc_results.append(np.mean(accuracies))\n",
    "\t\tval_acc_results.append(val_acc)\n",
    "\n",
    "\t\tprint(f\"Training loss: {np.mean(losses)} | Training acc: {np.mean(accuracies)} | Val loss: {val_loss} | Vall acc: {val_acc}\")\n",
    "\n",
    "\treturn train_acc_results,val_acc_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_train(fabric,\n",
    "\t\t\t\tmodel:Transformer,\n",
    "\t\t\t\tmask_function,\n",
    "\t\t\t\tx_train,\n",
    "\t\t\t\ty_train,\n",
    "\t\t\t\tx_test,\n",
    "\t\t\t\ty_test,\n",
    "\t\t\t\tbatch_size,\n",
    "\t\t\t\tn_epochs,):\n",
    "\t\n",
    "\tloss_fn = nn.CrossEntropyLoss(reduce=True,ignore_index=-100)\n",
    "\t\n",
    "\tdef loss_acc(fabric,\n",
    "\t\t\t  model:Transformer,\n",
    "\t\t\t  x_batch,\n",
    "\t\t\t  y_batch,\n",
    "\t\t\t  model_mask,\n",
    "\t\t\t  loss_mask):\n",
    "\t\t\t\n",
    "\t\twith fabric.autocast():\n",
    "\n",
    "\t\t\tx_batch = x_batch.to(DEVICE)\n",
    "\t\t\ty_batch = y_batch.to(DEVICE)\n",
    "\t\t\tmodel_mask = model_mask.to(DEVICE)\n",
    "\t\t\tloss_mask = loss_mask.to(DEVICE)\n",
    "\t\t\n",
    "\t\t\ty_pred = model.lm_forward(x_batch,model_mask)\n",
    "\t\t\ty_batch[torch.logical_not(loss_mask)] = -100\n",
    "\t\t\tloss = loss_fn(einx.rearrange(\"b l c -> b c l\",y_pred),y_batch)\n",
    "\t\t\tacc = masked_accuracy(y_pred,y_batch,loss_mask)\n",
    "\t\treturn loss,acc\n",
    "\n",
    "\t\n",
    "\tdef val_loop(fabric,\n",
    "\t\t\t  model:Transformer,\n",
    "\t\t\t  x_test,\n",
    "\t\t\t  y_test,\n",
    "\t\t\t  batch_size,):\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tbatches = get_batch_idx(len(x_test),batch_size,False)\n",
    "\n",
    "\t\tval_losses = []\n",
    "\t\tval_acc = []\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\n",
    "\t\t\tfor b,indices in enumerate(batches):\n",
    "\n",
    "\t\t\t\tx_batch = x_test[indices]\n",
    "\t\t\t\ty_batch = y_test[indices]\n",
    "\n",
    "\t\t\t\tpad_mask = mask_from_list(x_batch,[0,1])\n",
    "\n",
    "\t\t\t\tmasked = mask_function(pad_mask)\n",
    "\n",
    "\t\t\t\tloss,acc = loss_acc(fabric,model,x_batch,y_batch,masked,masked)\n",
    "\t\t\t\tval_losses.append(loss.item())\n",
    "\t\t\t\tval_acc.append(acc.item())\n",
    "\n",
    "\t\treturn np.mean(val_losses),np.mean(val_acc)\n",
    "\t\n",
    "\toptimizer = torch.optim.AdamW(model.parameters(),\n",
    "\t\t\t\t\t\t\t   lr=1E-3,\n",
    "\t\t\t\t\t\t\t   weight_decay=1E-2)\n",
    "\t\n",
    "\tmodel,optimizer = fabric.setup(model,optimizer)\n",
    "\n",
    "\tval_acc_results = []\n",
    "\ttrain_acc_results = []\n",
    "\n",
    "\tfor epoch in range(n_epochs):\n",
    "\n",
    "\t\tbatches = get_batch_idx(len(x_train),batch_size,True)\n",
    "\n",
    "\t\tlosses = []\n",
    "\t\taccuracies = []\n",
    "\n",
    "\t\tfor b,indices in enumerate(batches):\n",
    "\n",
    "\t\t\tx_batch = x_train[indices]\n",
    "\t\t\ty_batch = y_train[indices]\n",
    "\n",
    "\t\t\t# mask pad tokens\n",
    "\n",
    "\t\t\tpad_mask = mask_from_list(x_batch,[0,1])\n",
    "\n",
    "\t\t\t# mask (for language modeling)\n",
    "\n",
    "\t\t\tmasked = mask_function(pad_mask)\n",
    "\n",
    "\t\t\tloss,acc = loss_acc(fabric,model,x_batch,y_batch,masked,masked)\n",
    "\n",
    "\t\t\tfabric.backward(loss)\n",
    "\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\t\tlosses.append(loss.item())\n",
    "\t\t\taccuracies.append(acc.item())\n",
    "\n",
    "\t\tval_loss,val_acc = val_loop(fabric,model,x_test,y_test,batch_size,)\n",
    "\n",
    "\t\ttrain_acc_results.append(np.mean(accuracies))\n",
    "\t\tval_acc_results.append(val_acc)\n",
    "\n",
    "\t\tprint(f\"Training loss: {np.mean(losses)} | Training acc: {np.mean(accuracies)} | Val loss: {val_loss} | Vall acc: {val_acc}\")\n",
    "\n",
    "\treturn train_acc_results,val_acc_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n"
     ]
    }
   ],
   "source": [
    "fabric = Fabric(accelerator=\"cuda\",precision=\"bf16-mixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_mask(pad_mask):\n",
    "\treturn torch.logical_not(pad_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_mask(pad_mask,p=0.1):\n",
    "\tmask = torch.rand((pad_mask.shape))>(1-p)\n",
    "\treturn torch.logical_and(mask,torch.logical_not(pad_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "fabric_train = lambda x : torch_train(x,\n",
    "\t\t\t\t\t\t\t\t\t  model=model,\n",
    "\t\t\t\t\t\t\t\t\t  mask_function=structure_mask,\n",
    "\t\t\t\t\t\t\t\t\t  x_train=x_train,\n",
    "\t\t\t\t\t\t\t\t\t  y_train=y_train,\n",
    "\t\t\t\t\t\t\t\t\t  x_test=x_test,\n",
    "\t\t\t\t\t\t\t\t\t  y_test=y_test,\n",
    "\t\t\t\t\t\t\t\t\t  batch_size=32,\n",
    "\t\t\t\t\t\t\t\t\t  n_epochs=50,)\n",
    "\n",
    "fabric_lm_train = lambda x : lm_train(x,\n",
    "\t\t\t\t\t\t\t\t\t  model=hyena_model,\n",
    "\t\t\t\t\t\t\t\t\t  mask_function=lm_mask,\n",
    "\t\t\t\t\t\t\t\t\t  x_train=x_train,\n",
    "\t\t\t\t\t\t\t\t\t  y_train=x_train,\n",
    "\t\t\t\t\t\t\t\t\t  x_test=x_test,\n",
    "\t\t\t\t\t\t\t\t\t  y_test=x_test,\n",
    "\t\t\t\t\t\t\t\t\t  batch_size=32,\n",
    "\t\t\t\t\t\t\t\t\t  n_epochs=50,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[219], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfabric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfabric_lm_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rahar\\anaconda3\\envs\\neuro\\lib\\site-packages\\lightning\\fabric\\fabric.py:862\u001b[0m, in \u001b[0;36mFabric.launch\u001b[1;34m(self, function, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher, (_MultiProcessingLauncher, _XLALauncher)):\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo spawn processes with the `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` strategy, `.launch()` needs to be called\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with a function that contains the code to launch in processes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    861\u001b[0m     )\n\u001b[1;32m--> 862\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_and_launch(function, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rahar\\anaconda3\\envs\\neuro\\lib\\site-packages\\lightning\\fabric\\fabric.py:948\u001b[0m, in \u001b[0;36mFabric._wrap_and_launch\u001b[1;34m(self, to_run, *args, **kwargs)\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (launcher \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy\u001b[38;5;241m.\u001b[39mlauncher) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m launcher\u001b[38;5;241m.\u001b[39mlaunch(to_run, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m to_run(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rahar\\anaconda3\\envs\\neuro\\lib\\site-packages\\lightning\\fabric\\fabric.py:953\u001b[0m, in \u001b[0;36mFabric._wrap_with_setup\u001b[1;34m(self, to_run, *args, **kwargs)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy\u001b[38;5;241m.\u001b[39msetup_environment()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _replace_dunder_methods(DataLoader, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m), _replace_dunder_methods(BatchSampler):\n\u001b[1;32m--> 953\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m to_run(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[214], line 11\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m fabric_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x : torch_train(x,\n\u001b[0;32m      2\u001b[0m \t\t\t\t\t\t\t\t\t  model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m      3\u001b[0m \t\t\t\t\t\t\t\t\t  mask_function\u001b[38;5;241m=\u001b[39mstructure_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \t\t\t\t\t\t\t\t\t  batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m      9\u001b[0m \t\t\t\t\t\t\t\t\t  n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,)\n\u001b[1;32m---> 11\u001b[0m fabric_lm_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x : \u001b[43mlm_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m\t\t\t\t\t\t\t\t\t  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyena_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m\t\t\t\t\t\t\t\t\t  \u001b[49m\u001b[43mmask_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlm_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m\t\t\t\t\t\t\t\t\t  \u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m\t\t\t\t\t\t\t\t\t  \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m\t\t\t\t\t\t\t\t\t  \u001b[49m\u001b[43mx_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m\t\t\t\t\t\t\t\t\t  \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m\t\t\t\t\t\t\t\t\t  \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m\t\t\t\t\t\t\t\t\t  \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[210], line 92\u001b[0m, in \u001b[0;36mlm_train\u001b[1;34m(fabric, model, mask_function, x_train, y_train, x_test, y_test, batch_size, n_epochs)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# mask (for language modeling)\u001b[39;00m\n\u001b[0;32m     90\u001b[0m masked \u001b[38;5;241m=\u001b[39m mask_function(pad_mask)\n\u001b[1;32m---> 92\u001b[0m loss,acc \u001b[38;5;241m=\u001b[39m \u001b[43mloss_acc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfabric\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmasked\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmasked\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m fabric\u001b[38;5;241m.\u001b[39mbackward(loss)\n\u001b[0;32m     96\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[210], line 22\u001b[0m, in \u001b[0;36mlm_train.<locals>.loss_acc\u001b[1;34m(fabric, model, x_batch, y_batch, model_mask, loss_mask)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_acc\u001b[39m(fabric,\n\u001b[0;32m     14\u001b[0m \t\t  model:Transformer,\n\u001b[0;32m     15\u001b[0m \t\t  x_batch,\n\u001b[0;32m     16\u001b[0m \t\t  y_batch,\n\u001b[0;32m     17\u001b[0m \t\t  model_mask,\n\u001b[0;32m     18\u001b[0m \t\t  loss_mask):\n\u001b[0;32m     20\u001b[0m \t\u001b[38;5;28;01mwith\u001b[39;00m fabric\u001b[38;5;241m.\u001b[39mautocast():\n\u001b[1;32m---> 22\u001b[0m \t\tx_batch \u001b[38;5;241m=\u001b[39m \u001b[43mx_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \t\ty_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     24\u001b[0m \t\tmodel_mask \u001b[38;5;241m=\u001b[39m model_mask\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "fabric.launch(fabric_lm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahar\\AppData\\Local\\Temp\\ipykernel_49520\\927992485.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_batch = torch.tensor(x_train[0:16])\n"
     ]
    }
   ],
   "source": [
    "x_batch = torch.tensor(x_train[0:16])\n",
    "\n",
    "pad_mask = mask_from_list(x_batch,[0,1])\n",
    "\n",
    "masked = lm_mask(pad_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15,  9,  9,  ...,  0,  0,  0],\n",
       "        [20, 15, 18,  ...,  0,  0,  0],\n",
       "        [ 4,  7,  4,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 9, 21, 12,  ...,  0,  0,  0],\n",
       "        [ 7, 15, 12,  ...,  0,  0,  0],\n",
       "        [18,  5,  9,  ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[248], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mx_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "x_batch.to(torch.long).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[242], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mx_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "x_batch.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[225], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m hyena_model\u001b[38;5;241m.\u001b[39mlm_forward(\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m,masked\u001b[38;5;241m.\u001b[39mto(DEVICE))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "hyena_model.lm_forward(x_train.to(DEVICE),masked.to(DEVI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rahar\\anaconda3\\envs\\neuro\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[249], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlm_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfabric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyena_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mmask_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlm_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mx_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[210], line 92\u001b[0m, in \u001b[0;36mlm_train\u001b[1;34m(fabric, model, mask_function, x_train, y_train, x_test, y_test, batch_size, n_epochs)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# mask (for language modeling)\u001b[39;00m\n\u001b[0;32m     90\u001b[0m masked \u001b[38;5;241m=\u001b[39m mask_function(pad_mask)\n\u001b[1;32m---> 92\u001b[0m loss,acc \u001b[38;5;241m=\u001b[39m \u001b[43mloss_acc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfabric\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmasked\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmasked\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m fabric\u001b[38;5;241m.\u001b[39mbackward(loss)\n\u001b[0;32m     96\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[210], line 22\u001b[0m, in \u001b[0;36mlm_train.<locals>.loss_acc\u001b[1;34m(fabric, model, x_batch, y_batch, model_mask, loss_mask)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_acc\u001b[39m(fabric,\n\u001b[0;32m     14\u001b[0m \t\t  model:Transformer,\n\u001b[0;32m     15\u001b[0m \t\t  x_batch,\n\u001b[0;32m     16\u001b[0m \t\t  y_batch,\n\u001b[0;32m     17\u001b[0m \t\t  model_mask,\n\u001b[0;32m     18\u001b[0m \t\t  loss_mask):\n\u001b[0;32m     20\u001b[0m \t\u001b[38;5;28;01mwith\u001b[39;00m fabric\u001b[38;5;241m.\u001b[39mautocast():\n\u001b[1;32m---> 22\u001b[0m \t\tx_batch \u001b[38;5;241m=\u001b[39m \u001b[43mx_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \t\ty_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     24\u001b[0m \t\tmodel_mask \u001b[38;5;241m=\u001b[39m model_mask\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "lm_train(fabric,\n",
    "\t\tmodel=hyena_model,\n",
    "\t\tmask_function=lm_mask,\n",
    "\t\tx_train=x_train,\n",
    "\t\ty_train=x_train,\n",
    "\t\tx_test=x_test, \n",
    "\t\ty_test=x_test,\n",
    "\t\tbatch_size=32,\n",
    "\t\tn_epochs=50,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 32])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyena_model.embeddings.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "\tnormalize_mat = F.normalize(hyena_model.embeddings.weight,dim=1)\n",
    "\tmat = einx.dot(\"n1 d,n2 d -> n1 n2\",normalize_mat,normalize_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2738a558d00>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mat.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 3,\n",
       " 'D': 4,\n",
       " 'S': 5,\n",
       " 'Q': 6,\n",
       " 'K': 7,\n",
       " 'I': 8,\n",
       " 'P': 9,\n",
       " 'T': 10,\n",
       " 'F': 11,\n",
       " 'N': 12,\n",
       " 'G': 13,\n",
       " 'H': 14,\n",
       " 'L': 15,\n",
       " 'R': 16,\n",
       " 'W': 17,\n",
       " 'A': 18,\n",
       " 'V': 19,\n",
       " 'E': 20,\n",
       " 'Y': 21,\n",
       " 'M': 22,\n",
       " '<PAD>': 0,\n",
       " '<MASK>': 1,\n",
       " '<END>': 0}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amino_to_int_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define amino acid groups\n",
    "hydrophobic = ['A', 'V', 'I', 'L', 'M', 'F', 'W', 'Y']\n",
    "polar = ['S', 'T', 'N', 'Q', 'C', 'G']\n",
    "acidic = ['D', 'E']\n",
    "basic = ['K', 'R', 'H']\n",
    "special = ['P']\n",
    "\n",
    "\n",
    "\n",
    "# Group order by type\n",
    "grouped_amino_acids = hydrophobic + polar + acidic + basic + special\n",
    "grouped_amino_acids_indices = [amino_to_int_dict[aa] for aa in grouped_amino_acids if aa in amino_to_int_dict]\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "\t# Reorder the embedding matrix\n",
    "\treordered_embedding_matrix = hyena_model.embeddings.weight[grouped_amino_acids_indices, :]\n",
    "\tnormalize_mat = F.normalize(reordered_embedding_matrix,dim=1)\n",
    "\tmat = einx.dot(\"n1 d,n2 d -> n1 n2\",normalize_mat,normalize_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 19, 8, 15, 22, 11, 17, 21, 5, 10, 12, 6, 3, 13, 4, 20, 7, 16, 14, 9]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_amino_acids_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 20])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(mat.cpu(), xticklabels=grouped_amino_acids, yticklabels=grouped_amino_acids, cmap=\"viridis\", annot=False)\n",
    "plt.title(\"Cosine Similarity Matrix of Amino Acids\")\n",
    "plt.xlabel(\"Amino Acids\")\n",
    "plt.ylabel(\"Amino Acids\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'V',\n",
       " 'I',\n",
       " 'L',\n",
       " 'M',\n",
       " 'F',\n",
       " 'W',\n",
       " 'Y',\n",
       " 'S',\n",
       " 'T',\n",
       " 'N',\n",
       " 'Q',\n",
       " 'C',\n",
       " 'G',\n",
       " 'D',\n",
       " 'E',\n",
       " 'K',\n",
       " 'R',\n",
       " 'H',\n",
       " 'P']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_amino_acids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
