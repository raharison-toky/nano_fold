{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import flax.linen as nn\n",
    "from typing import Sequence\n",
    "import einx\n",
    "import optax\n",
    "from jax import random\n",
    "import numpy as np\n",
    "import jmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://rocm.blogs.amd.com/artificial-intelligence/jax-mixed-precision/README.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_PATH = \"training_data/labels.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 14:56:08.392768: W external/xla/xla/service/gpu/nvptx_compiler.cc:765] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.5.82). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "key = jax.random.key(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get input output matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "with open(TRAINING_PATH) as f:\n",
    "\tfor i in f:\n",
    "\t\tlines.append(i)\n",
    "\n",
    "n_sequences = len(lines)//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'>d2bkma | 128\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-HHHHH--HHHHHHHHHHHHHHHHH----HHHH----HHHHHHHHHHHHHHHH----------HHHHH------HHHHHHHHHHHHHHHHHH---HHHHHHHHHHHHHHHHHH---\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "\n",
    "for i in range(n_sequences):\n",
    "\tseq_id,seq_len = (lines[i*3]).split(\" | \")\n",
    "\tassert seq_id[0] == \">\"\n",
    "\tseq_id = seq_id[1:]\n",
    "\tseq_len = int(seq_len)\n",
    "\tseq = lines[i*3+1].strip()\n",
    "\tlabels = lines[i*3+2].strip()\n",
    "\n",
    "\tsequences.append([seq_id,seq,labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5326"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(5185, dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.argmax(jnp.array([len(i[1]) for i in sequences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = jnp.array([len(i[1]) for i in sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([116, 128, 147, ..., 111, 124, 119], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.07341345, dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lengths>384).sum()/len(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d3elka',\n",
       " 'TRERILHGLITLYILKELVKRPHGYELQKSFETTGQALPQGSIYILLKTKERGFVISESSVNKGQQLTVYHITDAGKKFLDHSQALQLARKIIDDLLSTVD',\n",
       " '---HHHHHHHHHHHHHHHHH---HHHHHHHHH---------HHHHHHHHHHH---------------------HHHHHHH----HHHHHHHHHHHHHH---']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'CYS': 'C', 'ASP': 'D', 'SER': 'S', 'GLN': 'Q', 'LYS': 'K',\n",
    "     'ILE': 'I', 'PRO': 'P', 'THR': 'T', 'PHE': 'F', 'ASN': 'N', \n",
    "     'GLY': 'G', 'HIS': 'H', 'LEU': 'L', 'ARG': 'R', 'TRP': 'W', \n",
    "     'ALA': 'A', 'VAL':'V', 'GLU': 'E', 'TYR': 'Y', 'MET': 'M'}\n",
    "\n",
    "amino_acids = list(d.values())\n",
    "\n",
    "amino_to_int_dict = {i:idx+3 for idx,i in enumerate(amino_acids)}\n",
    "amino_to_int_dict[\"<PAD>\"] = 0\n",
    "amino_to_int_dict[\"<MASK>\"] = 1\n",
    "amino_to_int_dict[\"<END>\"] = 0\n",
    "int_to_amino_dict = {v:k for v,k in amino_to_int_dict.items()}\n",
    "\n",
    "secondary_to_int_dict = {\"<PAD>\":2,\"-\":0,\"H\":1,\"<END>\":0}\n",
    "int_to_secondary_dict = {v:k for v,k in secondary_to_int_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_from_dict(sequence,tokenizer_dict,length=None):\n",
    "\n",
    "\tif length is None:\n",
    "\t\tlength = len(sequence)\n",
    "\n",
    "\tseq = []\n",
    "\n",
    "\tfor i in range(length):\n",
    "\n",
    "\t\tif i>len(sequence):\n",
    "\t\t\tseq.append(tokenizer_dict[\"<PAD>\"])\n",
    "\t\telif i == len(sequence):\n",
    "\t\t\tseq.append(tokenizer_dict[\"<END>\"])\n",
    "\t\telse:\n",
    "\t\t\tseq.append(tokenizer_dict[sequence[i]])\n",
    "\n",
    "\treturn jnp.array(seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "labels = []\n",
    "\n",
    "l_max = 384\n",
    "\n",
    "for seq in sequences:\n",
    "\tif len(seq[1])<=l_max-1:\n",
    "\t\tinputs.append(tokenize_from_dict(seq[1],amino_to_int_dict,l_max))\n",
    "\t\tlabels.append(tokenize_from_dict(seq[2],secondary_to_int_dict,l_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy(sequences,l_max):\n",
    "\n",
    "\tinputs = []\n",
    "\tlabels = []\n",
    "\n",
    "\tfor seq in sequences:\n",
    "\t\tif len(seq[1])<=l_max-1:\n",
    "\t\t\tinputs.append(tokenize_from_dict(seq[1],amino_to_int_dict,l_max))\n",
    "\t\t\tlabels.append(tokenize_from_dict(seq[2],secondary_to_int_dict,l_max))\n",
    "\n",
    "\treturn jnp.stack(inputs),jnp.stack(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs,labels = get_xy(sequences,384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4934, 384)\n",
      "(4934, 384)\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorizedConv(nn.Module):\n",
    "\tfeature:int\n",
    "\tkernel_size:int\n",
    "\n",
    "\t@nn.compact\n",
    "\tdef __call__(self,x):\n",
    "\t\tx = nn.Dense(self.feature)(x)\n",
    "\t\tx = nn.Conv(self.feature,self.kernel_size,feature_group_count=self.feature)(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\tfeatures: Sequence[int]\n",
    "\n",
    "\t@nn.compact\n",
    "\tdef __call__(self,x):\n",
    "\t\tfor feature in self.features[:-1]:\n",
    "\t\t\tx = nn.relu(FactorizedConv(feature,3)(x))\n",
    "\t\tx = FactorizedConv(self.features[-1],3)(x)\n",
    "\t\tx = nn.LayerNorm()(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongConvBlock(nn.Module):\n",
    "\tfeatures: Sequence[int]\n",
    "\tkernel_size:int\n",
    "\n",
    "\t@nn.compact\n",
    "\tdef __call__(self,x):\n",
    "\t\tfor feature in self.features[:-1]:\n",
    "\t\t\tx = nn.relu(FactorizedConv(feature,self.kernel_size)(x))\n",
    "\t\tx = FactorizedConv(self.features[-1],3)(x)\n",
    "\t\tx = nn.LayerNorm()(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin_pos_encode(x):\n",
    "\tembeddings = jnp.zeros((x.shape))\n",
    "\tbatch,length,dim = x.shape\n",
    "\tposition = jnp.arange(0,length)\n",
    "\tomega = jnp.exp(jnp.arange(0,dim,2) * math.log(10000)/dim)\n",
    "\tembeddings = embeddings.at[:,:,0::2].set(jnp.sin(einx.multiply(\"l,d -> l d\",position,omega)))\n",
    "\tembeddings = embeddings.at[:,:,1::2].set(jnp.cos(einx.multiply(\"l,d -> l d\",position,omega)))\n",
    "\n",
    "\treturn embeddings + x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2560000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512*5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedMHA(nn.Module):\n",
    "\thidden_dim:int\n",
    "\theads:int\n",
    "\n",
    "\t@nn.compact\n",
    "\tdef __call__(self,x,mask):\n",
    "\n",
    "\t\tproj = nn.Dense(3*self.hidden_dim)(x)\n",
    "\n",
    "\t\tq,k,v = einx.rearrange(\"b l (k d) -> k b l d\",proj,k=3)\n",
    "\n",
    "\t\tq = q * ((q.shape[-1] // self.heads) ** -0.5)\n",
    "\t\tattn = einx.dot(\"b q (h c), b k (h c) -> b q k h\", q, k, h=self.heads)\n",
    "\n",
    "\t\tattn = einx.where(\"b k, b q k h,\", mask, attn, -jnp.inf)\n",
    "\n",
    "\t\tattn = einx.softmax(\"b q [k] h\", attn)\n",
    "\t\ty = einx.dot(\"b q k h, b k (h c) -> b q (h c)\", attn, v)\n",
    "\n",
    "\t\treturn x + y\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "\thidden_dim:int\n",
    "\theads:int\n",
    "\texpansion_factor:int\n",
    "\n",
    "\t@nn.compact\n",
    "\tdef __call__(self,x,mask):\n",
    "\n",
    "\t\tx = x + nn.LayerNorm()(MaskedMHA(hidden_dim=self.hidden_dim,heads=self.heads)(x,mask))\n",
    "\t\tx = x + nn.LayerNorm()(MLP([self.hidden_dim*self.expansion_factor,self.hidden_dim])(x))\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\tn_amino:int\n",
    "\tamino_dim:int\n",
    "\tn_heads:int\n",
    "\tn_layers:int\n",
    "\texpansion_factor:int\n",
    "\n",
    "\t@nn.compact\n",
    "\tdef __call__(self,x,mask):\n",
    "\t\tx = nn.Embed(self.n_amino,self.amino_dim)(x)\n",
    "\t\tx = sin_pos_encode(x)\n",
    "\n",
    "\t\tfor _ in range(self.n_layers):\n",
    "\t\t\tx = EncoderBlock(self.amino_dim,self.n_heads,self.expansion_factor)(x,mask)\n",
    "\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLM(nn.Module):\n",
    "\tn_amino:int\n",
    "\tamino_dim:int\n",
    "\tn_heads:int\n",
    "\tn_layers:int\n",
    "\texpansion_factor:int\n",
    "\n",
    "\tdef setup(self):\n",
    "\n",
    "\t\tself.transformer = Transformer(n_amino=self.n_amino,\n",
    "\t\t\t\t\t\t\t\t amino_dim=self.amino_dim,\n",
    "\t\t\t\t\t\t\t\t n_heads=self.n_heads,\n",
    "\t\t\t\t\t\t\t\t n_layers=self.n_layers,\n",
    "\t\t\t\t\t\t\t\t expansion_factor=self.expansion_factor)\n",
    "\t\t\n",
    "\t\tself.layer_norm = nn.LayerNorm()\n",
    "\t\tself.masked_lm_head = nn.Dense(self.n_amino)\n",
    "\t\tself.structure_head = nn.Dense(2)\n",
    "\n",
    "\tdef __call__(self,x,mask):\n",
    "\n",
    "\t\tx = self.transformer(x,mask)\n",
    "\t\tx = self.layer_norm(x)\n",
    "\t\treturn x\n",
    "\t\n",
    "\tdef lm_forward(self,x,mask):\n",
    "\t\tx = self(x,mask)\n",
    "\t\treturn self.masked_lm_head(x)\n",
    "\t\n",
    "\tdef structure_forward(self,x,mask):\n",
    "\t\tx = self(x,mask)\n",
    "\t\treturn self.structure_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_from_list(x,values):\n",
    "\n",
    "\tmask = jnp.zeros_like(x,dtype=jnp.bool)\n",
    "\n",
    "\tfor i in values:\n",
    "\t\tmask += (x == i)\n",
    "\n",
    "\treturn mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(amino_to_int_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaskedLM(n_amino=len(amino_to_int_dict),\n",
    "\t\t\t\t\tamino_dim=32,\n",
    "\t\t\t\t\tn_heads=2,\n",
    "\t\t\t\t\tn_layers=6,\n",
    "\t\t\t\t\texpansion_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 14:56:28.598416: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[16,64,256]{2,1,0}, u8[0]{0}) custom-call(f32[16,64,256]{2,1,0}, f32[64,1,3]{2,1,0}), window={size=3 pad=1_1}, dim_labels=bf0_oi0->bf0, feature_group_count=64, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-19 14:56:29.077847: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.47952694s\n",
      "Trying algorithm eng0{} for conv (f32[16,64,256]{2,1,0}, u8[0]{0}) custom-call(f32[16,64,256]{2,1,0}, f32[64,1,3]{2,1,0}), window={size=3 pad=1_1}, dim_labels=bf0_oi0->bf0, feature_group_count=64, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n"
     ]
    }
   ],
   "source": [
    "batch = jnp.ones((16,256),dtype=jnp.int32)\n",
    "model_var = model.init(key,batch,mask_from_list(batch,[0]),method=\"structure_forward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[3m                                MaskedLM Summary                                \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams       \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│               │ MaskedLM      │ -             │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[2,384]  │              │               │\n",
      "│               │               │ - \u001b[2mbool\u001b[0m[2,384] │              │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer   │ Transformer   │ -             │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[2,384]  │              │               │\n",
      "│               │               │ - \u001b[2mbool\u001b[0m[2,384] │              │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Embed         │ \u001b[2mint32\u001b[0m[2,384]  │ \u001b[2mfloat32\u001b[0m[2,3… │ embedding:    │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[23,3… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m736 \u001b[0m\u001b[1;2m(2.9 KB)\u001b[0m  │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ EncoderBlock  │ -             │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[2,38… │              │               │\n",
      "│               │               │ - \u001b[2mbool\u001b[0m[2,384] │              │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ MaskedMHA     │ -             │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[2,38… │              │               │\n",
      "│               │               │ - \u001b[2mbool\u001b[0m[2,384] │              │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Dense         │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[96]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32,9… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m3,168 \u001b[0m\u001b[1;2m(12.7 \u001b[0m  │\n",
      "│               │               │               │              │ \u001b[1;2mKB)\u001b[0m           │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ LayerNorm     │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ scale:        │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ MLP           │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ FactorizedCo… │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Dense         │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[64]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32,6… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m2,112 \u001b[0m\u001b[1;2m(8.4 \u001b[0m   │\n",
      "│               │               │               │              │ \u001b[1;2mKB)\u001b[0m           │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Conv          │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[64]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[3,1,… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m256 \u001b[0m\u001b[1;2m(1.0 KB)\u001b[0m  │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ FactorizedCo… │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Dense         │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[64,3… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m2,080 \u001b[0m\u001b[1;2m(8.3 \u001b[0m   │\n",
      "│               │               │               │              │ \u001b[1;2mKB)\u001b[0m           │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Conv          │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[3,1,… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m   │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ LayerNorm     │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ scale:        │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ LayerNorm     │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ scale:        │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ EncoderBlock  │ -             │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[2,38… │              │               │\n",
      "│               │               │ - \u001b[2mbool\u001b[0m[2,384] │              │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ MaskedMHA     │ -             │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[2,38… │              │               │\n",
      "│               │               │ - \u001b[2mbool\u001b[0m[2,384] │              │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Dense         │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[96]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32,9… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m3,168 \u001b[0m\u001b[1;2m(12.7 \u001b[0m  │\n",
      "│               │               │               │              │ \u001b[1;2mKB)\u001b[0m           │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ LayerNorm     │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ scale:        │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ MLP           │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ FactorizedCo… │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Dense         │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[64]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32,6… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m2,112 \u001b[0m\u001b[1;2m(8.4 \u001b[0m   │\n",
      "│               │               │               │              │ \u001b[1;2mKB)\u001b[0m           │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Conv          │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[64]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[3,1,… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m256 \u001b[0m\u001b[1;2m(1.0 KB)\u001b[0m  │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ FactorizedCo… │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Dense         │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[64,3… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m2,080 \u001b[0m\u001b[1;2m(8.3 \u001b[0m   │\n",
      "│               │               │               │              │ \u001b[1;2mKB)\u001b[0m           │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Conv          │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[3,1,… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m   │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ LayerNorm     │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ scale:        │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ LayerNorm     │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ scale:        │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ EncoderBlock  │ -             │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[2,38… │              │               │\n",
      "│               │               │ - \u001b[2mbool\u001b[0m[2,384] │              │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ MaskedMHA     │ -             │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[2,38… │              │               │\n",
      "│               │               │ - \u001b[2mbool\u001b[0m[2,384] │              │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Dense         │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[96]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32,9… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m3,168 \u001b[0m\u001b[1;2m(12.7 \u001b[0m  │\n",
      "│               │               │               │              │ \u001b[1;2mKB)\u001b[0m           │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ LayerNorm     │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ scale:        │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ MLP           │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ FactorizedCo… │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Dense         │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[64]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32,6… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m2,112 \u001b[0m\u001b[1;2m(8.4 \u001b[0m   │\n",
      "│               │               │               │              │ \u001b[1;2mKB)\u001b[0m           │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Conv          │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[64]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[3,1,… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m256 \u001b[0m\u001b[1;2m(1.0 KB)\u001b[0m  │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ FactorizedCo… │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Dense         │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[64,3… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m2,080 \u001b[0m\u001b[1;2m(8.3 \u001b[0m   │\n",
      "│               │               │               │              │ \u001b[1;2mKB)\u001b[0m           │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Conv          │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[3,1,… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m   │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ LayerNorm     │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ scale:        │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ LayerNorm     │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ scale:        │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ EncoderBlock  │ -             │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[2,38… │              │               │\n",
      "│               │               │ - \u001b[2mbool\u001b[0m[2,384] │              │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ MaskedMHA     │ -             │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[2,38… │              │               │\n",
      "│               │               │ - \u001b[2mbool\u001b[0m[2,384] │              │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Dense         │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[96]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32,9… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m3,168 \u001b[0m\u001b[1;2m(12.7 \u001b[0m  │\n",
      "│               │               │               │              │ \u001b[1;2mKB)\u001b[0m           │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ LayerNorm     │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ scale:        │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ MLP           │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ FactorizedCo… │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Dense         │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[64]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32,6… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m2,112 \u001b[0m\u001b[1;2m(8.4 \u001b[0m   │\n",
      "│               │               │               │              │ \u001b[1;2mKB)\u001b[0m           │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Conv          │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[64]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[3,1,… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m256 \u001b[0m\u001b[1;2m(1.0 KB)\u001b[0m  │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ FactorizedCo… │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Dense         │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[64,3… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m2,080 \u001b[0m\u001b[1;2m(8.3 \u001b[0m   │\n",
      "│               │               │               │              │ \u001b[1;2mKB)\u001b[0m           │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Conv          │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[3,1,… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m   │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ LayerNorm     │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ scale:        │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ LayerNorm     │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ scale:        │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ EncoderBlock  │ -             │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[2,38… │              │               │\n",
      "│               │               │ - \u001b[2mbool\u001b[0m[2,384] │              │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ MaskedMHA     │ -             │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[2,38… │              │               │\n",
      "│               │               │ - \u001b[2mbool\u001b[0m[2,384] │              │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Dense         │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[96]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32,9… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m3,168 \u001b[0m\u001b[1;2m(12.7 \u001b[0m  │\n",
      "│               │               │               │              │ \u001b[1;2mKB)\u001b[0m           │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ LayerNorm     │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ scale:        │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ MLP           │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ FactorizedCo… │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Dense         │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[64]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32,6… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m2,112 \u001b[0m\u001b[1;2m(8.4 \u001b[0m   │\n",
      "│               │               │               │              │ \u001b[1;2mKB)\u001b[0m           │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Conv          │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[64]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[3,1,… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m256 \u001b[0m\u001b[1;2m(1.0 KB)\u001b[0m  │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ FactorizedCo… │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Dense         │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[64,3… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m2,080 \u001b[0m\u001b[1;2m(8.3 \u001b[0m   │\n",
      "│               │               │               │              │ \u001b[1;2mKB)\u001b[0m           │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Conv          │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[3,1,… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m   │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ LayerNorm     │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ scale:        │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ LayerNorm     │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ scale:        │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ EncoderBlock  │ -             │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[2,38… │              │               │\n",
      "│               │               │ - \u001b[2mbool\u001b[0m[2,384] │              │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ MaskedMHA     │ -             │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[2,38… │              │               │\n",
      "│               │               │ - \u001b[2mbool\u001b[0m[2,384] │              │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Dense         │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[96]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32,9… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m3,168 \u001b[0m\u001b[1;2m(12.7 \u001b[0m  │\n",
      "│               │               │               │              │ \u001b[1;2mKB)\u001b[0m           │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ LayerNorm     │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ scale:        │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ MLP           │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ FactorizedCo… │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Dense         │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[64]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32,6… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m2,112 \u001b[0m\u001b[1;2m(8.4 \u001b[0m   │\n",
      "│               │               │               │              │ \u001b[1;2mKB)\u001b[0m           │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Conv          │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[64]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[3,1,… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m256 \u001b[0m\u001b[1;2m(1.0 KB)\u001b[0m  │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ FactorizedCo… │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │               │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Dense         │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[64,3… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m2,080 \u001b[0m\u001b[1;2m(8.3 \u001b[0m   │\n",
      "│               │               │               │              │ \u001b[1;2mKB)\u001b[0m           │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ Conv          │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ kernel:       │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[3,1,… │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m   │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ LayerNorm     │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ scale:        │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ transformer/… │ LayerNorm     │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ scale:        │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│ layer_norm    │ LayerNorm     │ \u001b[2mfloat32\u001b[0m[2,38… │ \u001b[2mfloat32\u001b[0m[2,3… │ bias:         │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │ scale:        │\n",
      "│               │               │               │              │ \u001b[2mfloat32\u001b[0m[32]   │\n",
      "│               │               │               │              │               │\n",
      "│               │               │               │              │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼──────────────┼───────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m       Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m48,416 \u001b[0m\u001b[1;2m(193.7\u001b[0m\u001b[1m \u001b[0m│\n",
      "│\u001b[1m               \u001b[0m│\u001b[1m               \u001b[0m│\u001b[1m               \u001b[0m│\u001b[1m              \u001b[0m│\u001b[1m \u001b[0m\u001b[1;2mKB)\u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0m│\n",
      "└───────────────┴───────────────┴───────────────┴──────────────┴───────────────┘\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m                      Total Parameters: 48,416 \u001b[0m\u001b[1;2m(193.7 KB)\u001b[0m\u001b[1m                       \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(nn.tabulate(model,key)(inputs[0:2],mask_from_list(inputs[0:2],[0,1,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_cross_entropy_loss(logits, labels, mask):\n",
    "    loss = optax.softmax_cross_entropy(logits, one_hot(labels, logits.shape[-1]))\n",
    "    masked_loss = loss * mask\n",
    "    return jnp.sum(masked_loss) / jnp.sum(mask)\n",
    "\n",
    "def one_hot(x, num_classes):\n",
    "    return jnp.eye(num_classes)[x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(vars,x,mask,y,pred_mask):\n",
    "\n",
    "\ty_pred = model.apply(vars,x,mask,method=MaskedLM.structure_forward)\n",
    "\tloss = masked_cross_entropy_loss(y_pred,y,pred_mask)\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def masked_accuracy(logits, labels, mask):\n",
    "    predictions = jnp.argmax(logits, axis=-1)\n",
    "    correct_predictions = (predictions == labels) * mask\n",
    "    accuracy = jnp.sum(correct_predictions) / jnp.sum(mask)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(key,x,y,p):\n",
    "\n",
    "\tpermutations = random.permutation(key,jnp.arange(len(x)))\n",
    "\tp = int(len(x)*p)\n",
    "\n",
    "\treturn x[permutations[:p]],y[permutations[:p]],x[permutations[p:]],y[permutations[p:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test,y_test,x_train,y_train = train_val_split(key,inputs,labels,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_idx(key,n,batch_size,shuffle=True):\n",
    "\n",
    "\tif shuffle:\n",
    "\t\tpermutations = random.permutation(key,jnp.arange(n))\n",
    "\telse:\n",
    "\t\tpermutations = jnp.arange(n)\n",
    "\t\n",
    "\tpermutations = permutations[0:batch_size*(n//batch_size)]\n",
    "\tbatches = einx.rearrange(\"(n b) -> n b\",permutations,b=batch_size)\n",
    "\n",
    "\treturn batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = jmp.Policy(\n",
    "    param_dtype=jnp.float32,\n",
    "    compute_dtype=jnp.bfloat16 if amp else jnp.float32,\n",
    "    output_dtype=jnp.bfloat16 if amp else jnp.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_mask(pad_mask,p=0.1):\n",
    "\tmask = random.uniform((pad_mask.shape))>(1-p)\n",
    "\treturn jnp.logical_and(mask,jnp.logical_not(pad_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_mask(pad_mask):\n",
    "\treturn jnp.logical_not(pad_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_train(model,\n",
    "\t\t\t\t key,\n",
    "\t\t\t\t model_var,\n",
    "\t\t\t\t mask_function,\n",
    "\t\t\t\t x_train,\n",
    "\t\t\t\t y_train,\n",
    "\t\t\t\t x_test,\n",
    "\t\t\t\t y_test,\n",
    "\t\t\t\t batch_size,\n",
    "\t\t\t\t forward,\n",
    "\t\t\t\t n_epochs,\n",
    "\t\t\t\t policy,):\n",
    "\t\n",
    "\tdef loss_fn(vars,x,mask,y,pred_mask,loss_scale):\n",
    "\n",
    "\t\ty_pred = model.apply(vars,x,mask,method=forward)\n",
    "\t\tloss = masked_cross_entropy_loss(y_pred,y,pred_mask)\n",
    "\t\tacc = masked_accuracy(y_pred,y,pred_mask)\n",
    "\t\tloss = loss_scale.scale(loss)\n",
    "\t\treturn loss,(acc)\n",
    "\t\n",
    "\tdef val_loop(model_var,\n",
    "\t\t\t key,\n",
    "\t\t\t x_test,\n",
    "\t\t\t y_test,\n",
    "\t\t\t batch_size,\n",
    "\t\t\t func,\n",
    "\t\t\t loss_scale):\n",
    "\t\t\n",
    "\t\tbatches = get_batch_idx(key,len(x_test),batch_size,False) \n",
    "\n",
    "\t\tval_losses = []\n",
    "\t\tval_acc = []\n",
    "\n",
    "\t\tparams = policy.cast_to_compute(model_var)\n",
    "\n",
    "\t\tfor b,indices in enumerate(batches):\n",
    "\n",
    "\t\t\tx_batch = x_test[indices]\n",
    "\t\t\ty_batch = y_test[indices]\n",
    "\n",
    "\t\t\tpad_mask = mask_from_list(x_batch,[0,1])\n",
    "\n",
    "\t\t\tmasked = mask_function(pad_mask)\n",
    "\n",
    "\t\t\tloss,(acc)= func(model_var,x_batch,pad_mask,y_batch,masked,loss_scale)\n",
    "\n",
    "\t\t\tloss = loss_scale.unscale(loss)\n",
    "\n",
    "\t\t\tval_losses.append(loss.item())\n",
    "\t\t\tval_acc.append(acc)\n",
    "\n",
    "\t\treturn np.mean(val_losses),np.mean(val_acc)\n",
    "\t\n",
    "\n",
    "\t\n",
    "\toptimizer = optax.adamw(learning_rate=1E-3,weight_decay=1E-2)\n",
    "\topt_state = optimizer.init(model_var)\n",
    "\tloss_grad_fn = jax.value_and_grad(loss_fn,has_aux=True)\n",
    "\tloss_grad_fn = jax.jit(loss_grad_fn)\n",
    "\tjit_loss_acc = jax.jit(loss_fn)\n",
    "\n",
    "\tloss_scale = jmp.DynamicLossScale(jnp.float32(2**15))\n",
    "\n",
    "\tskip_infinite = isinstance(loss_scale, jmp.DynamicLossScale)\n",
    "\n",
    "\tval_acc_results = []\n",
    "\ttrain_acc_results = []\n",
    "\n",
    "\tfor epoch in range(n_epochs):\n",
    "\n",
    "\t\tbatches = get_batch_idx(key,len(x_train),batch_size,True)\n",
    "\n",
    "\t\tlosses = []\n",
    "\t\taccuracies = []\n",
    "\n",
    "\t\tfor b,indices in enumerate(batches):\n",
    "\n",
    "\t\t\tparams = policy.cast_to_compute(model_var)\n",
    "\n",
    "\t\t\tx_batch = x_train[indices]\n",
    "\t\t\ty_batch = y_train[indices]\n",
    "\n",
    "\t\t\tpad_mask = mask_from_list(x_batch,[0,1])\n",
    "\n",
    "\t\t\tmasked = mask_function(pad_mask)\n",
    "\n",
    "\t\t\t(loss,(acc)),grad = loss_grad_fn(params,x_batch,pad_mask,y_batch,masked,loss_scale)\n",
    "\n",
    "\t\t\tloss = loss_scale.unscale(loss)\n",
    "\n",
    "\t\t\tgrad = policy.cast_to_param(grad)\n",
    "\n",
    "\t\t\tgrad = loss_scale.unscale(grad)\n",
    "\n",
    "\t\t\tif skip_infinite:\n",
    "\t\t\t\tgrad_finite = jmp.all_finite(grad)\n",
    "\t\t\t\tloss_scale = loss_scale.adjust(grad_finite)\n",
    "\t\t\t\tupdates,opt_state = optimizer.update(grad,opt_state,model_var)\n",
    "\t\t\t\tmodel_var = jmp.select_tree(grad_finite,optax.apply_updates(model_var,updates),\n",
    "\t\t\t\t\t\t\t model_var)\n",
    "\t\t\t\t\n",
    "\t\t\telse:\n",
    "\t\t\t\tupdates,opt_state = optimizer.update(grad,opt_state,model_var)\n",
    "\t\t\t\tmodel_var = optax.apply_updates(model_var,updates)\n",
    "\n",
    "\t\t\tlosses.append(loss.item())\n",
    "\t\t\taccuracies.append(acc)\n",
    "\n",
    "\t\tval_loss,val_acc = val_loop(model_var,key,x_test,y_test,batch_size,jit_loss_acc,loss_scale)\n",
    "\n",
    "\t\ttrain_acc_results.append(np.mean(accuracies))\n",
    "\t\tval_acc_results.append(val_acc)\n",
    "\n",
    "\t\tprint(f\"Training loss: {np.mean(losses)} | Training acc: {np.mean(accuracies)} | Val loss: {val_loss} | Vall acc: {val_acc}\")\n",
    "\n",
    "\treturn train_acc_results,val_acc_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6563976382556027 | Training acc: 0.6213165521621704 | Val loss: 0.5877815910748073 | Vall acc: 0.6895515322685242\n",
      "Training loss: 0.5719930345881475 | Training acc: 0.7028025984764099 | Val loss: 0.5539684125355312 | Vall acc: 0.715394914150238\n",
      "Training loss: 0.5513856719209723 | Training acc: 0.7193717956542969 | Val loss: 0.5428883177893502 | Vall acc: 0.7256947755813599\n",
      "Training loss: 0.5419283098962209 | Training acc: 0.726730227470398 | Val loss: 0.5371461851256234 | Vall acc: 0.7306972742080688\n",
      "Training loss: 0.5361941842591926 | Training acc: 0.7311421036720276 | Val loss: 0.5332152162279401 | Vall acc: 0.7337771654129028\n",
      "Training loss: 0.5320346102322617 | Training acc: 0.7339268922805786 | Val loss: 0.5299125228609357 | Vall acc: 0.7356956601142883\n",
      "Training loss: 0.5281043593605904 | Training acc: 0.7369402050971985 | Val loss: 0.527338581425803 | Vall acc: 0.7390700578689575\n",
      "Training loss: 0.521378271383782 | Training acc: 0.7421257495880127 | Val loss: 0.5170573932783944 | Vall acc: 0.7448530197143555\n",
      "Training loss: 0.499841377343217 | Training acc: 0.7585811614990234 | Val loss: 0.4969582089356014 | Vall acc: 0.7584267258644104\n",
      "Training loss: 0.4823726138023481 | Training acc: 0.7708783745765686 | Val loss: 0.48797199555805754 | Vall acc: 0.7643525004386902\n",
      "Training loss: 0.4733346761905984 | Training acc: 0.7770562171936035 | Val loss: 0.48039059553827557 | Vall acc: 0.7680469751358032\n",
      "Training loss: 0.4668471286558125 | Training acc: 0.7812960147857666 | Val loss: 0.4762711099215916 | Vall acc: 0.7711798548698425\n",
      "Training loss: 0.46126205116918645 | Training acc: 0.784447431564331 | Val loss: 0.47140858854566303 | Vall acc: 0.7752218246459961\n",
      "Training loss: 0.4566342342798024 | Training acc: 0.7874518036842346 | Val loss: 0.46894713810511995 | Vall acc: 0.7769074440002441\n",
      "Training loss: 0.4526186416002169 | Training acc: 0.7901182770729065 | Val loss: 0.46717038324901033 | Vall acc: 0.7781224250793457\n",
      "Training loss: 0.4492328544593837 | Training acc: 0.7920594811439514 | Val loss: 0.4653494230338505 | Vall acc: 0.7795776128768921\n",
      "Training loss: 0.44617613109007276 | Training acc: 0.7939074039459229 | Val loss: 0.46469748871667044 | Vall acc: 0.7802042961120605\n",
      "Training loss: 0.4430268986584389 | Training acc: 0.7961457371711731 | Val loss: 0.46415784529277254 | Vall acc: 0.7796316146850586\n",
      "Training loss: 0.43968480253872805 | Training acc: 0.797888457775116 | Val loss: 0.46272910067013334 | Vall acc: 0.7817449569702148\n",
      "Training loss: 0.4369942988843134 | Training acc: 0.7992202639579773 | Val loss: 0.462227212531226 | Vall acc: 0.7835457921028137\n",
      "Training loss: 0.4345398579966532 | Training acc: 0.8007944226264954 | Val loss: 0.4627828981195177 | Vall acc: 0.7823905944824219\n",
      "Training loss: 0.43251618926655755 | Training acc: 0.8020898699760437 | Val loss: 0.4605780243873596 | Vall acc: 0.7851081490516663\n",
      "Training loss: 0.42991813792757794 | Training acc: 0.8035427331924438 | Val loss: 0.4594315120152065 | Vall acc: 0.7860246300697327\n",
      "Training loss: 0.4276985170906537 | Training acc: 0.8049483895301819 | Val loss: 0.46114145857947214 | Vall acc: 0.7846420407295227\n",
      "Training loss: 0.42592220518687 | Training acc: 0.8057570457458496 | Val loss: 0.45997525112969534 | Vall acc: 0.7855461835861206\n",
      "Training loss: 0.42368369151468144 | Training acc: 0.8071481585502625 | Val loss: 0.46264101352010456 | Vall acc: 0.7836310267448425\n",
      "Training loss: 0.42115938193994024 | Training acc: 0.8083519339561462 | Val loss: 0.4635409116744995 | Vall acc: 0.7828508019447327\n",
      "Training loss: 0.41947370788005933 | Training acc: 0.8093430995941162 | Val loss: 0.46420128856386456 | Vall acc: 0.7835081219673157\n",
      "Training loss: 0.41760289975225107 | Training acc: 0.8108227252960205 | Val loss: 0.4637525464807238 | Vall acc: 0.7824376225471497\n",
      "Training loss: 0.41670865371619187 | Training acc: 0.8115179538726807 | Val loss: 0.46650141903332304 | Vall acc: 0.7825596928596497\n",
      "Training loss: 0.41421780112671525 | Training acc: 0.8127735257148743 | Val loss: 0.4634519006524767 | Vall acc: 0.7831980586051941\n",
      "Training loss: 0.41256257442578875 | Training acc: 0.81385737657547 | Val loss: 0.46725039396967205 | Vall acc: 0.7823616862297058\n",
      "Training loss: 0.410272212265289 | Training acc: 0.8152579665184021 | Val loss: 0.4661737765584673 | Vall acc: 0.7835984230041504\n",
      "Training loss: 0.4093810740399034 | Training acc: 0.8156823515892029 | Val loss: 0.4657380240304129 | Vall acc: 0.7840989232063293\n",
      "Training loss: 0.4079423011982278 | Training acc: 0.8163496851921082 | Val loss: 0.4661024681159428 | Vall acc: 0.7829047441482544\n",
      "Training loss: 0.40668879673905567 | Training acc: 0.8168443441390991 | Val loss: 0.46348383171217783 | Vall acc: 0.7844434976577759\n",
      "Training loss: 0.4060634194988094 | Training acc: 0.817523717880249 | Val loss: 0.46435638836451937 | Vall acc: 0.7843865156173706\n",
      "Training loss: 0.40348368862720385 | Training acc: 0.8189994096755981 | Val loss: 0.46798345020839144 | Vall acc: 0.7829920649528503\n",
      "Training loss: 0.4020034260537526 | Training acc: 0.8199059367179871 | Val loss: 0.4679803337369646 | Vall acc: 0.7826770544052124\n",
      "Training loss: 0.4002156327032063 | Training acc: 0.8208410143852234 | Val loss: 0.46669877001217436 | Vall acc: 0.7848224639892578\n",
      "Training loss: 0.39825041510470927 | Training acc: 0.8220465779304504 | Val loss: 0.4680634183543069 | Vall acc: 0.7823881506919861\n",
      "Training loss: 0.39744369073273383 | Training acc: 0.8223722577095032 | Val loss: 0.46929225751331877 | Vall acc: 0.7814465761184692\n",
      "Training loss: 0.3971773328846448 | Training acc: 0.822399377822876 | Val loss: 0.4741375744342804 | Vall acc: 0.7803853154182434\n",
      "Training loss: 0.3955706964208655 | Training acc: 0.8233029842376709 | Val loss: 0.4719024215425764 | Vall acc: 0.7792742848396301\n",
      "Training loss: 0.39460499666325033 | Training acc: 0.8238298892974854 | Val loss: 0.47433883803231375 | Vall acc: 0.7784551978111267\n",
      "Training loss: 0.3927604204987826 | Training acc: 0.8248818516731262 | Val loss: 0.47658704434122356 | Vall acc: 0.7798687219619751\n",
      "Training loss: 0.3914230880263734 | Training acc: 0.82586270570755 | Val loss: 0.4741598239966801 | Vall acc: 0.7797823548316956\n",
      "Training loss: 0.38973613205837876 | Training acc: 0.8261330723762512 | Val loss: 0.47818356326648165 | Vall acc: 0.7789878249168396\n",
      "Training loss: 0.3885402226284759 | Training acc: 0.8272580504417419 | Val loss: 0.48032343813351225 | Vall acc: 0.7781697511672974\n",
      "Training loss: 0.3870455783932176 | Training acc: 0.8277059197425842 | Val loss: 0.48156489218984333 | Vall acc: 0.7775856256484985\n"
     ]
    }
   ],
   "source": [
    "train_acc,val_acc = custom_train(model=model,\n",
    "\t\t\t key=key,\n",
    "\t\t\t model_var=model_var,\n",
    "\t\t\t x_train=x_train,\n",
    "\t\t\t y_train=y_train,\n",
    "\t\t\t x_test=x_test,\n",
    "\t\t\t y_test=y_test,\n",
    "\t\t\t batch_size=32,\n",
    "\t\t\t forward=MaskedLM.structure_forward,\n",
    "\t\t\t mask_function=structure_mask,\n",
    "\t\t\t n_epochs=50,\n",
    "\t\t\t policy=policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f970c7f2650>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We first have to worry about processing\n",
    "1. We need to get the data into lists of tuples (sequence,length,labels)\n",
    "2. We tokenize the sequences and binarize the labels\n",
    "3. We construct (tokenized) input/output sequences with maximum length\n",
    "4. Probably select a cutoff length\n",
    "   - let's say 512\n",
    "\n",
    "- Once we have the inputs and output pairs we can move into training\n",
    "- Implementing the neural network is trivial and independent of the task\n",
    "- Afterwards, there are two ways of training the neural network\n",
    "  - direct supervised training\n",
    "  - masked language modeling - as you would with AlphaFold,ESMFold,... - followed by supervised training\n",
    "  - this is a cute blog post\n",
    "\n",
    "- There are \"only\" like 5000 sequences which may be somewhat small for deep-learning applications (unclear with masked modeling?)\n",
    "  - in any case, we may want to perform data augmentation by randomly switching similar amino-acids together?\n",
    "  - the other option would be to reduce the dictionnary size?\n",
    "    - I feel like having augmentations would have the same effect as restricting the dictionnary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
